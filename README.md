# Indian Market Scraper

A Java-based application for scraping, processing, and analyzing Indian market data.  
This project collects raw market data (such as signals, news, and stock-related information), cleans and deduplicates it, applies text/vector analysis, and stores the results in a structured format (Parquet).

---

## ðŸš€ Features
- *Data Collection:* Scrapes market-related signals using custom collectors.  
- *Data Cleaning:* Removes duplicates and applies preprocessing.  
- *Analysis Layer:* Supports TF-IDF vectorization and aggregation of signals.  
- *Scheduling:* Automated jobs to collect and process data periodically.  
- *Storage:* Saves processed data into *Parquet* format for scalability.  
- *Modular Architecture:* Separate layers for collector, analysis, process, storage, and services.  

---

## ðŸ›  Tech Stack
- *Language:* Java 17+  
- *Framework:* Spring Boot  
- *Build Tool:* Maven  
- *Libraries:*  
  - Spring Web (REST APIs)  
  - Spring Scheduling  
  - Apache Parquet  
  - Apache Commons / Guava  
  - (Optional) NLP libraries for text analysis  

---

## AApproach /Workflow
Data Collection (Collector Layer)
	â€¢	NitterScraper fetches market-related signals and sentiment data.
	â€¢	Collector is designed to be extensible for future data sources.
	2.	Processing & Cleaning (Process Layer)
	â€¢	Cleaner normalizes raw inputs.
	â€¢	Deduplicator removes duplicate entries to improve data accuracy.
	3.	Analysis (Analysis Layer)
	â€¢	TfidfVectorizer converts text into numerical features.
	â€¢	SignalAggregator combines multiple sources into a unified signal.
	4.	Scheduling & Automation (Service Layer)
	â€¢	ScheduledJob triggers scraping and processing at regular intervals.
	â€¢	Ensures real-time updates without manual effort.
	5.	Storage (Storage Layer)
	â€¢	ParquetWriterService saves processed data in Parquet format for efficient analytics.
	â€¢	Optimized for large-scale queries and reporting.
	6.	API / Controller Layer
	â€¢	SignalController exposes REST APIs to access processed insights.
	â€¢	Supports integration with dashboards and external systems.

ðŸ”¹ End-to-End Workflow
	1.	Scrape raw signals from market/social sources.
	2.	Clean, filter, and deduplicate data.
	3.	Apply TF-IDF vectorization and signal aggregation.
	4.	Store the results in optimized Parquet files.
	5.	Serve insights via REST API.
	6.	Automate the full cycle using scheduled jobs.

## ðŸ“‚ Project Structure
indian-market-scraper/
â”‚â”€â”€ .mvn/                   # Maven wrapper
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/example/indian_market_scraper/
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SignalAggregator.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TfidfVectorizer.java
â”‚   â”‚   â”‚   â”œâ”€â”€ collector/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ NitterScraper.java
â”‚   â”‚   â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SignalController.java
â”‚   â”‚   â”‚   â”œâ”€â”€ process/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Cleaner.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Deduplicator.java
â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ScheduledJob.java
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ParquetWriterService.java
â”‚   â”‚   â”‚   â”œâ”€â”€ IndianMarketScraperApplication.java
â”‚   â”‚   â”œâ”€â”€ resources/       # application.properties
â”‚   â”œâ”€â”€ test/                # Unit/Integration tests
â”‚â”€â”€ target/                  # Build output



## ScreenShots
Screenshots-
--Project 
--Classes
--Result